{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SURGE Demo\n",
    "\n",
    "Here, we simulate some data eQTL data (where the eQTL effect sizes change as function context) and assess SURGE's ability to re-capture the uknown contexts.\n",
    "\n",
    "This notebook should also provide an example of how SURGE can be easily run within python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import surge.surge_inference\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate some data\n",
    "\n",
    "To assess SURGE's ability to accurately capture contexts underlying context-specific eQTLs, we perform the following simulation experiment:\n",
    "\n",
    "We randomly generated genotype and expression matrices across $T$ variant-gene-pairs and $N$ RNA samples. For each simulated variant-gene pair, we simulated the genotype vector ($G$) across the $N$ samples according to the following probability distributions:\n",
    "\n",
    "$af_n \\sim Uniform(.1,.9)$\n",
    "\n",
    "$G_n \\sim Binomial(2, af_n)$\n",
    "\n",
    "Then we standardized genotype to have mean 0 and variance 1. We call the standardized genotype in the nth sample $G^*_n$\n",
    "\n",
    "Next, we simulated the expression vector (y) across the $N$ samples using the following probability distributions (conditional on the simulated standardized genotype):\n",
    "\n",
    "$y_n \\sim N(\\mu + \\beta G^*_n +\\sum_k G^*_n *U_{nk} V_k \\theta_k, 1)$\n",
    "\n",
    "$\\mu \\sim N(0,1)$\n",
    "\n",
    "$\\beta \\sim N(0,1)$\n",
    "\n",
    "$U_{nk} \\sim N(0,1)$\n",
    "\n",
    "$V_k \\sim N(0, \\gamma)$\n",
    "\n",
    "$\\theta_k \\sim Bernoulli(p)$\n",
    "\n",
    "\n",
    "\n",
    "This simulation, therefor, evaluates SURGE's ability to re-capture the simulated latent contexts (U) as a function of the simulation hyper-parameters:\n",
    "- The number of latent contexts (K; num_components)\n",
    "- The sample size (N; num_samples)\n",
    "- The strength of the interaction terms ($\\gamma$, t_statistic)\n",
    "- The fraction of tests that are context-specific eQTLs for a particular context ($p$; missingness_fraction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate genotype vector for a particular snp\n",
    "def get_genotype_vec(num_samples, af):\n",
    "    allele1 = np.random.binomial(n=1, p=af,size=num_samples)\n",
    "    allele2 = np.random.binomial(n=1, p=af,size=num_samples)\n",
    "    genotype_vec = allele1 + allele2\n",
    "    return genotype_vec\n",
    "\n",
    "\n",
    "def standardize_variance_ratio_between_expression_and_genotype(Y, G):\n",
    "    num_tests = Y.shape[1]\n",
    "    for test_num in range(num_tests):\n",
    "        test_sdev = np.std(Y[:, test_num]/G[:,test_num])\n",
    "        G[:, test_num] = G[:, test_num]*test_sdev\n",
    "    G = G/np.std(G)\n",
    "    return G\n",
    "\n",
    "# Generate gene expression data (Y), and genotype data (G)\n",
    "def generate_eqtl_factorization_data_with_no_sample_repeat(num_samples, num_tests, num_components, t_statistic, missingness_fraction):\n",
    "    # Simulate genotype\n",
    "    G = np.zeros((num_samples, num_tests))\n",
    "    G_raw = np.zeros((num_samples, num_tests))\n",
    "    for test_num in range(num_tests):\n",
    "        af = np.random.uniform(.1,.9)\n",
    "        # Get genotype for this particular snp\n",
    "        genotype_vec = get_genotype_vec(num_samples, af)\n",
    "        G_raw[:, test_num] = genotype_vec\n",
    "        # Standardized genotype\n",
    "        G[:, test_num] = (genotype_vec - np.mean(genotype_vec))/np.std(genotype_vec)\n",
    "\n",
    "    # Simulate U\n",
    "    U = np.random.standard_normal(size=(num_samples, num_components))\n",
    "    for component_num in range(num_components):\n",
    "        U[:, component_num] = (U[:, component_num] - np.mean(U[:, component_num]))/np.std(U[:, component_num])\n",
    "    \n",
    "    # Simulate V\n",
    "    V = np.random.normal(loc=0.0, scale=t_statistic, size=(num_components, num_tests))\n",
    "    # Add missingness to V\n",
    "    for test_num in range(num_tests):\n",
    "        for component_num in range(num_components):\n",
    "            V[component_num, test_num] = V[component_num, test_num]*np.random.binomial(n=1,p=missingness_fraction)\n",
    "\n",
    "    # Get Expected expression value of each (sample, gene) pair\n",
    "    predicted_mean = np.zeros((num_samples, num_tests))  + G*np.dot(U,V)\n",
    "    # Simulate genotype fixed effect size\n",
    "    betas = []\n",
    "    Y = np.zeros((num_samples, num_tests))\n",
    "    for test_num in range(num_tests):\n",
    "        beta = np.random.normal(loc=0.0, scale=.1)\n",
    "        predicted_mean[:, test_num] = predicted_mean[:, test_num] + G[:, test_num]*beta\n",
    "        Y[:, test_num] = np.random.normal(predicted_mean[:,test_num])\n",
    "        betas.append(beta)\n",
    "    \n",
    "    # Standardized Y\n",
    "    for test_num in range(num_tests):\n",
    "        Y[:, test_num] = (Y[:, test_num] - np.mean(Y[:, test_num]))/np.std(Y[:, test_num])\n",
    "    \n",
    "    # Scale genotype vector for each test by the standard deviation of Y/G\n",
    "    # This scaling encourages the low-dimensional factorization (UV) to explain variance equally across tests\n",
    "    G = standardize_variance_ratio_between_expression_and_genotype(Y, G)\n",
    "    \n",
    "    return Y, G, np.asarray(betas), U, V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "num_samples = 250\n",
    "num_tests=1000\n",
    "t_statistic = .75\n",
    "missingness_fraction = .3\n",
    "simulated_factor = 5\n",
    "np.random.seed(2)\n",
    "\n",
    "# Simulate the data\n",
    "Y, G, betas, U_sim, V_sim = generate_eqtl_factorization_data_with_no_sample_repeat(num_samples, num_tests, simulated_factor, t_statistic, missingness_fraction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SURGE\n",
    "\n",
    "At this point we have successfully simulated eQTL data. Notably we have generated an standardized expression matrix ($Y$) of dimension $N$X$T$ and we have generated a standardized genotype matrix ($G^*$) of dimension $N$X$T$. The $t^{th}$ column of $Y$ reflects the gene corresponding to the $t^{th}$ variant-gene pair. The $t^{th}$ column of $G$ reflects the variant corresponding to the $t^{th}$ variant-gene pair. Notably, each column of $Y$ has mean 0 and stardard deviation 1. Additionally, each column of $G$ has mean 0 and is scaled by the standard deviation of Y[:, t]/G[:, t]. This scaling encourages the low-dimensional factorization (UV) to explain variance equally across tests.\n",
    "\n",
    "Using this simulated data, we can run SURGE to re-discover the simulated contexts.\n",
    "\n",
    "It is important to note that this simulated expression was not affected by covariates nor was simulated expression affected by sample repeat structure . Therefore, we ran we ran SURGE:\n",
    "- We did not model the effects of covariates on gene expression in SURGE. However, covariates could be easily included by changing cov into a matrix that contains a column for each covariate (as well as column corresponding to the intercept). \n",
    "- We did not model the effects of sample repeat structure on gene expression in SURGE. However, sample repeat structure could easily be included by setting `re_boolean=True`, and by including `z=sample_repeat` as an arguement in `fit`. `sample_repeat` is a vector of length $N$ where each element is an integer corresponding to the individual that sample came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************\n",
      "SURGE\n",
      "Single cell Unsupervised Regulation of Gene Expression\n",
      "*********************************************************\n",
      "###############################\n",
      "Initialize variables\n",
      "###############################\n",
      "250 samples detected\n",
      "1000 tests detected\n",
      "10 latent factors detected\n",
      "###############################\n",
      "Begin Coordinate ascent variational inference (CAVI) iterative algorithm\n",
      "###############################\n",
      "Variational Inference iteration: 0\n",
      "delta ELBO: 129674150.70252755\n",
      "Variational Inference iteration: 1\n",
      "delta ELBO: 10254.893435208302\n",
      "Variational Inference iteration: 2\n",
      "delta ELBO: 10361.034078769677\n",
      "Variational Inference iteration: 3\n",
      "delta ELBO: 15470.044559486385\n",
      "Variational Inference iteration: 4\n",
      "delta ELBO: 11611.206279800623\n",
      "Variational Inference iteration: 5\n",
      "delta ELBO: 5047.356142696401\n",
      "Variational Inference iteration: 6\n",
      "delta ELBO: 1008.8867376417038\n",
      "Variational Inference iteration: 7\n",
      "delta ELBO: 539.8357458042447\n",
      "Variational Inference iteration: 8\n",
      "delta ELBO: 383.829210777767\n",
      "Variational Inference iteration: 9\n",
      "delta ELBO: 303.6326084063621\n",
      "Variational Inference iteration: 10\n",
      "delta ELBO: 253.88291971263243\n",
      "Variational Inference iteration: 11\n",
      "delta ELBO: 220.02055898768594\n",
      "Variational Inference iteration: 12\n",
      "delta ELBO: 195.66701056598686\n",
      "Variational Inference iteration: 13\n",
      "delta ELBO: 177.47954272676725\n",
      "Variational Inference iteration: 14\n",
      "delta ELBO: 163.50744771712925\n",
      "Variational Inference iteration: 15\n",
      "delta ELBO: 152.54612642363645\n",
      "Variational Inference iteration: 16\n",
      "delta ELBO: 143.8455118301208\n",
      "Variational Inference iteration: 17\n",
      "delta ELBO: 136.95241987943882\n",
      "Variational Inference iteration: 18\n",
      "delta ELBO: 131.60114719183184\n",
      "Variational Inference iteration: 19\n",
      "delta ELBO: 127.62554776843172\n",
      "Variational Inference iteration: 20\n",
      "delta ELBO: 124.89345004956704\n",
      "Variational Inference iteration: 21\n",
      "delta ELBO: 123.26776233920828\n",
      "Variational Inference iteration: 22\n",
      "delta ELBO: 122.58897448360221\n",
      "Variational Inference iteration: 23\n",
      "delta ELBO: 122.66718901117565\n",
      "Variational Inference iteration: 24\n",
      "delta ELBO: 123.27421515341848\n",
      "Variational Inference iteration: 25\n",
      "delta ELBO: 124.13534505944699\n",
      "Variational Inference iteration: 26\n",
      "delta ELBO: 124.93448041082593\n",
      "Variational Inference iteration: 27\n",
      "delta ELBO: 125.35866704920772\n",
      "Variational Inference iteration: 28\n",
      "delta ELBO: 125.19636576448102\n",
      "Variational Inference iteration: 29\n",
      "delta ELBO: 124.44590611482272\n",
      "Variational Inference iteration: 30\n",
      "delta ELBO: 123.3324482490425\n",
      "Variational Inference iteration: 31\n",
      "delta ELBO: 122.18674544960959\n",
      "Variational Inference iteration: 32\n",
      "delta ELBO: 121.2820447817212\n",
      "Variational Inference iteration: 33\n",
      "delta ELBO: 120.75415069778683\n",
      "Variational Inference iteration: 34\n",
      "delta ELBO: 120.61733005120186\n",
      "Variational Inference iteration: 35\n",
      "delta ELBO: 120.81262679788051\n",
      "Variational Inference iteration: 36\n",
      "delta ELBO: 121.24248016165802\n",
      "Variational Inference iteration: 37\n",
      "delta ELBO: 121.78642697434407\n",
      "Variational Inference iteration: 38\n",
      "delta ELBO: 122.31086935655912\n",
      "Variational Inference iteration: 39\n",
      "delta ELBO: 122.67957634397317\n",
      "Variational Inference iteration: 40\n",
      "delta ELBO: 122.7575457272469\n",
      "Variational Inference iteration: 41\n",
      "delta ELBO: 122.40645189746283\n",
      "Variational Inference iteration: 42\n",
      "delta ELBO: 121.51376542152138\n",
      "Variational Inference iteration: 43\n",
      "delta ELBO: 120.13200665207114\n",
      "Variational Inference iteration: 44\n",
      "delta ELBO: 118.69232202036073\n",
      "Variational Inference iteration: 45\n",
      "delta ELBO: 118.00400166609325\n",
      "Variational Inference iteration: 46\n",
      "delta ELBO: 118.84640690067317\n",
      "Variational Inference iteration: 47\n",
      "delta ELBO: 121.5555772666703\n",
      "Variational Inference iteration: 48\n",
      "delta ELBO: 126.03370147931855\n",
      "Variational Inference iteration: 49\n",
      "delta ELBO: 131.9495678964886\n",
      "Variational Inference iteration: 50\n",
      "delta ELBO: 138.80406207288615\n",
      "Variational Inference iteration: 51\n",
      "delta ELBO: 145.90264594898326\n",
      "Variational Inference iteration: 52\n",
      "delta ELBO: 152.37885966780595\n",
      "Variational Inference iteration: 53\n",
      "delta ELBO: 157.32447049184702\n",
      "Variational Inference iteration: 54\n",
      "delta ELBO: 160.016363181232\n",
      "Variational Inference iteration: 55\n",
      "delta ELBO: 160.16961211920716\n",
      "Variational Inference iteration: 56\n",
      "delta ELBO: 158.08690865512472\n",
      "Variational Inference iteration: 57\n",
      "delta ELBO: 154.58217419422\n",
      "Variational Inference iteration: 58\n",
      "delta ELBO: 150.61118679627543\n",
      "Variational Inference iteration: 59\n",
      "delta ELBO: 146.73188319813926\n",
      "Variational Inference iteration: 60\n",
      "delta ELBO: 142.96979304862907\n",
      "Variational Inference iteration: 61\n",
      "delta ELBO: 139.38233061187202\n",
      "Variational Inference iteration: 62\n",
      "delta ELBO: 136.28868624637835\n",
      "Variational Inference iteration: 63\n",
      "delta ELBO: 133.31546636903659\n",
      "Variational Inference iteration: 64\n",
      "delta ELBO: 128.13034958514618\n",
      "Variational Inference iteration: 65\n",
      "delta ELBO: 116.76528483524453\n",
      "Variational Inference iteration: 66\n",
      "delta ELBO: 97.56931670056656\n",
      "Variational Inference iteration: 67\n",
      "delta ELBO: 75.22252720576944\n",
      "Variational Inference iteration: 68\n",
      "delta ELBO: 56.45906165620545\n",
      "Variational Inference iteration: 69\n",
      "delta ELBO: 43.835820804641116\n",
      "Variational Inference iteration: 70\n",
      "delta ELBO: 36.13215019094059\n",
      "Variational Inference iteration: 71\n",
      "delta ELBO: 31.26569711987395\n",
      "Variational Inference iteration: 72\n",
      "delta ELBO: 27.77232325921068\n",
      "Variational Inference iteration: 73\n",
      "delta ELBO: 24.89526238711551\n",
      "Variational Inference iteration: 74\n",
      "delta ELBO: 22.306065940472763\n",
      "Variational Inference iteration: 75\n",
      "delta ELBO: 19.90038783143973\n",
      "Variational Inference iteration: 76\n",
      "delta ELBO: 17.68328057328472\n",
      "Variational Inference iteration: 77\n",
      "delta ELBO: 15.693692069267854\n",
      "Variational Inference iteration: 78\n",
      "delta ELBO: 13.957677371625323\n",
      "Variational Inference iteration: 79\n",
      "delta ELBO: 12.472513319924474\n",
      "Variational Inference iteration: 80\n",
      "delta ELBO: 11.212014486722182\n",
      "Variational Inference iteration: 81\n",
      "delta ELBO: 10.138378350355197\n",
      "Variational Inference iteration: 82\n",
      "delta ELBO: 9.212248169642407\n",
      "Variational Inference iteration: 83\n",
      "delta ELBO: 8.399582672747783\n",
      "Variational Inference iteration: 84\n",
      "delta ELBO: 7.675887097895611\n",
      "Variational Inference iteration: 85\n",
      "delta ELBO: 7.027200383134186\n",
      "Variational Inference iteration: 86\n",
      "delta ELBO: 6.44704621413257\n",
      "Variational Inference iteration: 87\n",
      "delta ELBO: 5.930812418926507\n",
      "Variational Inference iteration: 88\n",
      "delta ELBO: 5.471120986097958\n",
      "Variational Inference iteration: 89\n",
      "delta ELBO: 5.056858305993956\n",
      "Variational Inference iteration: 90\n",
      "delta ELBO: 4.675570200430229\n",
      "Variational Inference iteration: 91\n",
      "delta ELBO: 4.3168882394675165\n",
      "Variational Inference iteration: 92\n",
      "delta ELBO: 3.974758269963786\n",
      "Variational Inference iteration: 93\n",
      "delta ELBO: 3.6475648208288476\n",
      "Variational Inference iteration: 94\n",
      "delta ELBO: 3.336579008726403\n",
      "Variational Inference iteration: 95\n",
      "delta ELBO: 3.0438678617356345\n",
      "Variational Inference iteration: 96\n",
      "delta ELBO: 2.7707359040505253\n",
      "Variational Inference iteration: 97\n",
      "delta ELBO: 2.517172954045236\n",
      "Variational Inference iteration: 98\n",
      "delta ELBO: 2.282147061720025\n",
      "Variational Inference iteration: 99\n",
      "delta ELBO: 2.064272266754415\n",
      "Variational Inference iteration: 100\n",
      "delta ELBO: 1.8624178956379183\n",
      "Variational Inference iteration: 101\n",
      "delta ELBO: 1.6760229564388283\n",
      "Variational Inference iteration: 102\n",
      "delta ELBO: 1.5050735347904265\n",
      "Variational Inference iteration: 103\n",
      "delta ELBO: 1.349833138170652\n",
      "Variational Inference iteration: 104\n",
      "delta ELBO: 1.2104799859807827\n",
      "Variational Inference iteration: 105\n"
     ]
    }
   ],
   "source": [
    "# Covariate matrix is just an intercept as there are no simulated covariates\n",
    "cov = np.ones((num_samples, 1))\n",
    "\n",
    "# Create SURGE object (w/ no sample repeat structure): \n",
    "surge_obj = surge.surge_inference.SURGE_VI(K=10, re_boolean=False)\n",
    "surge_obj.fit(G=G, Y=Y, cov=cov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize learned SURGE latent contexts\n",
    "\n",
    "SURGE optimization has converged. We can now visualize the results. \n",
    "\n",
    "First, we can examine the ELBO over variational iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure ELBO is monotonically increasing (Note: ELBO is gauranteed to monotonically increase)\n",
    "plt.plot(surge_obj.elbo[1:]);  # Skipped first iteration in visualization b/c it is such a large change that it completely dominates the plot\n",
    "plt.xlabel('Iteration');\n",
    "plt.ylabel('ELBO');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot PVE by each of SURGE latent contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order SURGE contexts by PVE\n",
    "context_order = np.argsort(-surge_obj.factor_pve)\n",
    "# Plot PVE for each of latent contexts\n",
    "plt.plot(surge_obj.factor_pve[context_order], '-ok');\n",
    "plt.xlabel('Learned SURGE latent context');\n",
    "plt.ylabel('PVE');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 learned SURGE latent contenxts have non-zero PVE, whereas the other 5 SURGE latent contexts have approximately 0 PVE. This is expected given we simulated 5 latent contexts. \n",
    "\n",
    "Next, plot absolute correlation between learned SURGE latent contexts and simulated SURGE latent contexts. Here, we filter out non-informative learned latent contexts (ie those with PVE < 1e-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extact learned SURGE latent contexts (ordered by PVE)\n",
    "U_learned = surge_obj.U_mu[:, context_order]\n",
    "# Filter out contexts with PVE < 1e-4\n",
    "context_pves = surge_obj.factor_pve[context_order]\n",
    "U_learned = U_learned[:, context_pves >= 1e-4]\n",
    "\n",
    "# Compute correlations\n",
    "K_sim = U_sim.shape[1]\n",
    "K_learned = U_learned.shape[1]\n",
    "corr_mat = np.zeros((K_sim, K_learned))\n",
    "\n",
    "for k_sim in range(K_sim):\n",
    "    for k_learned in range(K_learned):\n",
    "        corr_mat[k_sim, k_learned] = np.corrcoef(U_sim[:, k_sim], U_learned[:, k_learned])[0,1]\n",
    "\n",
    "sns.heatmap(np.abs(corr_mat));\n",
    "plt.xlabel('Learned SURGE latent contexts');\n",
    "plt.ylabel('Simulated SURGE latent contexts');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the above heatmap, the learned SURGE latent contexts are well correlated with the simulated SURGE latent contexts. However, some of the simulated SURGE latent contexts are explained by multiple learned SURGE latent contexts. For example, learned SURGE latent context 1 is correlated (nearly equally) with simulated SURGE context 1 and 2. This result is unsuprising and is well-documented by dimensionality reduction theory: solutions are equivalent up to a rotation.\n",
    "\n",
    "Another way to view how well the learned SURGE latent contexts capture the simulated SURGE latent contexts is to ask of much of the variance in a simulated SURGE latent context is explained by all of the SURGE latent contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate R-squared in each simulated component\n",
    "r_squared = []\n",
    "for k_sim in range(K_sim):\n",
    "    reg = LinearRegression().fit(U_learned, U_sim[:,k_sim])\n",
    "    r_squared.append(reg.score(U_learned, U_sim[:,k_sim]))\n",
    "\n",
    "# Plot\n",
    "plt.plot(r_squared, '-ok');\n",
    "plt.xlabel('Simulated SURGE latent context');\n",
    "plt.ylabel('R^2');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract parameters from fitted SURGE object\n",
    "\n",
    "Now, we will go over some useful parameters to extract from the fitted SURGE object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Expected value of SURGE latent contexts.\n",
    "\n",
    "    This is a matrix of dimensions NXK where N is the number of samples and K is the number of latent contexts. An element of this matrix represents the estimated expected value of the SURGE latent context for a particular latent context for a particular sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(surge_obj.U_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Variance of SURGE latent contexts\n",
    "   \n",
    "    This a matrix of dimensions NXK where N is the number of samples and K is the number of latent contexts. An element of this matrix represents the estimated variance of the expected value of the SURGE latent contexts for a particular latent context for a particular sample.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surge_obj.U_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ELBO\n",
    "   \n",
    "    This a vector of length number of variational iterations where each element represents that elbo at each iteration. Note, this vector is gauranteed to be monotonically increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surge_obj.elbo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Percent variance explained of each of the SURGE latent contexts\n",
    "   \n",
    "    This is a vector of length number of latent contexts. Each element of this vector represents the PVE (Based on bottom of P21 of https://arxiv.org/pdf/1802.06931.pdf) of each of the SURGE latent contexts. Generally we filter out contexts based on those we PVE < 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surge_obj.factor_pve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Expected value of latent context effect sizes\n",
    "   \n",
    "    This is a matrix of dimensions KXT where T is the number of eqtl tests and K is the number of latent contexts. An element of this matrix represents the estimated interaction effect size corresponding to the latent context and eqtl of the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surge_obj.V_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Variance of latent context effect sizes\n",
    "   \n",
    "    This is a matrix of dimensions KXT where T is the number of eqtl tests and K is the number of latent contexts. An element of this matrix represents the estimated interaction effect size variance corresponding to the latent context and eqtl of the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(surge_obj.V_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
